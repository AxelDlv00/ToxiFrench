{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3b8249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.rich import tqdm\n",
    "from typing import Dict, Any, List\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import argparse\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "from utils.toxicity_predictor import ToxicityPredictor \n",
    "\n",
    "from utils.models.openai import GPTPredictor\n",
    "from utils.models.deepseek import DeepseekPredictor\n",
    "from utils.models.mistral_api import MistralAPIPredictor\n",
    "from utils.models.mistral_moderation import MistralModerationPredictor\n",
    "from utils.models.omni import OpenAIModerationPredictor\n",
    "from utils.models.perspective import PerspectiveAPIPredictor\n",
    "from utils.models.gemini import GeminiPredictor\n",
    "\n",
    "from utils.models.qwen25 import Qwen25Predictor\n",
    "from utils.models.qwen3 import Qwen3Predictor\n",
    "from utils.models.mistral_local import MistralPredictor\n",
    "from utils.models.llama_guard import LlamaGuardPredictor\n",
    "from utils.models.shieldgemma import ShieldGemmaPredictor\n",
    "\n",
    "from utils.models.camembert import CamemBertPredictor\n",
    "from utils.models.distilbert import DistilBertPredictor\n",
    "from utils.models.polyguard import PolyGuardPredictor\n",
    "from utils.models.roberta import ToxicBertPredictor\n",
    "\n",
    "from utils.models.toxifrench import ToxiFrenchPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81bd0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTOR_MAP = {\n",
    "    \"GPTPredictor\": GPTPredictor,\n",
    "    \"DeepseekPredictor\": DeepseekPredictor,\n",
    "    \"MistralAPIPredictor\": MistralAPIPredictor,\n",
    "    \"MistralModerationPredictor\": MistralModerationPredictor,\n",
    "    \"OpenAIModerationPredictor\": OpenAIModerationPredictor,\n",
    "    \"PerspectiveAPIPredictor\": PerspectiveAPIPredictor,\n",
    "    \"GeminiPredictor\": GeminiPredictor,\n",
    "    \"Qwen25Predictor\": Qwen25Predictor,\n",
    "    \"Qwen3Predictor\": Qwen3Predictor,\n",
    "    \"MistralPredictor\": MistralPredictor,\n",
    "    \"LlamaGuardPredictor\": LlamaGuardPredictor,\n",
    "    \"ShieldGemmaPredictor\": ShieldGemmaPredictor,\n",
    "    \"CamemBertPredictor\": CamemBertPredictor,\n",
    "    \"DistilBertPredictor\": DistilBertPredictor,\n",
    "    \"PolyGuardPredictor\": PolyGuardPredictor,\n",
    "    \"ToxicBertPredictor\": ToxicBertPredictor,\n",
    "    \"ToxiFrenchPredictor\": ToxiFrenchPredictor,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ece19af",
   "metadata": {},
   "outputs": [],
   "source": [
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7121e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path: str = \"config.json\") -> Dict[str, Any]:\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "def insert_examples(prompt, examples_toxic, examples_non_toxic):\n",
    "    \"\"\"\n",
    "    Insert examples into the prompt.\n",
    "    \"\"\"\n",
    "    def prompt_format(text, answer):\n",
    "        return f\"Message :\\n« {text} »\\nCe message est-il toxique ?\\n{answer}\"\n",
    "    toxic_examples = [prompt_format(ex, 'toxique') for ex in examples_toxic]\n",
    "    non_toxic_examples = [prompt_format(ex, 'non-toxique') for ex in examples_non_toxic]\n",
    "    examples = toxic_examples + non_toxic_examples\n",
    "    random.shuffle(examples)\n",
    "    return prompt.replace('<insert here>', '\\n\\n'.join(examples))\n",
    "\n",
    "def config_experiment(exp_name: str, config: Dict[str, Any]):\n",
    "    assert exp_name in config.keys(), f\"Experiment '{exp_name}' not found in configuration.\"\n",
    "\n",
    "    load_dotenv(dotenv_path=config['global']['env_dir'],override=True) \n",
    "    \n",
    "    experiment_config = config[exp_name].copy()\n",
    "    experiment_config['experiment_name'] = exp_name\n",
    "    experiment_config['benchmark'] = Path(config[\"global\"][\"benchmark_dir\"]) / config[exp_name].get(\"benchmark\")\n",
    "    experiment_config['output'] = Path(config[\"global\"][\"results_dir\"]) / config[exp_name].get(\"output\")\n",
    "\n",
    "    if \"api_key\" in config[exp_name]:\n",
    "        api_key_config = config[exp_name][\"api_key\"]\n",
    "        if api_key_config[\"type\"] == \"env\":\n",
    "            api_key = os.getenv(api_key_config[\"name\"])\n",
    "        elif api_key_config[\"type\"] == \"file\":\n",
    "            with open(api_key_config[\"path\"], 'r') as f:\n",
    "                api_key = f.read().strip()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported API key configuration type.\")\n",
    "        \n",
    "        experiment_config['api_key'] = api_key\n",
    "            \n",
    "    if \"system_prompt\" in config[exp_name]:\n",
    "        system_prompt_config = config[exp_name][\"system_prompt\"]\n",
    "        if system_prompt_config[\"type\"] == \"file\":\n",
    "            with open(system_prompt_config[\"path\"], 'r') as f:\n",
    "                system_prompt = f.read().strip()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported system prompt configuration type.\")\n",
    "        \n",
    "        experiment_config['system_prompt'] = system_prompt\n",
    "\n",
    "    if \"prompt_template\" in config[exp_name]:\n",
    "        prompt_template_config = config[exp_name][\"prompt_template\"]\n",
    "        if prompt_template_config[\"type\"] == \"file\":\n",
    "            with open(prompt_template_config[\"path\"], 'r') as f:\n",
    "                prompt_template = f.read().strip()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported prompt template configuration type.\")\n",
    "        if config[exp_name].get(\"few_shots_toxic\", 0) + config[exp_name].get(\"few_shots_non_toxic\", 0) > 0:\n",
    "            few_shots_toxic = config[exp_name].get(\"few_shots_toxic\", 0)\n",
    "            few_shots_non_toxic = config[exp_name].get(\"few_shots_non_toxic\", 0)\n",
    "            examples_toxic = config[\"global\"][\"few_shot_examples\"][\"toxic\"][:few_shots_toxic]\n",
    "            examples_non_toxic = config[\"global\"][\"few_shot_examples\"][\"non_toxic\"][:few_shots_non_toxic]\n",
    "            prompt_template = insert_examples(prompt_template, examples_toxic, examples_non_toxic)\n",
    "        experiment_config['prompt_template'] = prompt_template\n",
    "    \n",
    "    experiment_config['language'] = config[exp_name].get(\"language\", \"fr\")\n",
    "    experiment_config['max_retries'] = config[exp_name].get(\"max_retries\", 5)\n",
    "    experiment_config['delay_base'] = config[exp_name].get(\"delay_base\", 2)\n",
    "    experiment_config['parallel_requests'] = config[exp_name].get(\"parallel_requests\", 4)\n",
    "    return experiment_config\n",
    "\n",
    "\n",
    "def load_benchmark(exp_config: Dict[str, Any]) -> pd.DataFrame:\n",
    "    benchmark_path = exp_config['benchmark']\n",
    "    df = pd.read_csv(benchmark_path, encoding=\"utf-8\")\n",
    "    df = df.dropna(subset=[\"content\", \"label\"])\n",
    "    df[\"label\"] = df[\"label\"].astype(int)\n",
    "    return df\n",
    "\n",
    "def run_predictions(exp_config: Dict[str, Any], df: pd.DataFrame, result_dir: Path = Path(\"benchmarking/results\")):\n",
    "    predictor = PREDICTOR_MAP[exp_config['predictor']](exp_config)\n",
    "    predictor.initialise_predictor()\n",
    "\n",
    "    output = exp_config['output']\n",
    "    if not (result_dir / output).exists():\n",
    "        result_dir.mkdir(parents=True, exist_ok=True)\n",
    "        texts = df[\"content\"].tolist()\n",
    "        results = [None] * len(texts)\n",
    "    else:\n",
    "        existing_df = pd.read_csv(result_dir / output, encoding=\"utf-8\")\n",
    "        existing_texts = existing_df[\"content\"].tolist()\n",
    "        texts = df[~df[\"content\"].isin(existing_texts)][\"content\"].tolist()\n",
    "        results = existing_df[\"label\"].tolist() + [None] * len(texts)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=exp_config['parallel_requests']) as executor:\n",
    "        future_to_idx = {\n",
    "            executor.submit(predictor.predict, txt): idx\n",
    "            for idx, txt in enumerate(texts)\n",
    "        }\n",
    "        for future in tqdm(as_completed(future_to_idx), total=len(texts)):\n",
    "            idx = future_to_idx[future]\n",
    "            results[idx] = future.result()\n",
    "            if idx % 50 == 0:\n",
    "                pd.DataFrame({\"content\": texts, \"label\": results}).to_csv(output, index=False)\n",
    "                print(f\"Checkpoint saved at {output}\")\n",
    "    \n",
    "    pd.DataFrame({\"content\": texts, \"label\": results}).to_csv(output, index=False)\n",
    "    print(f\"Final results saved at {output}\")\n",
    "\n",
    "def evaluate_predictions(exp_config: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Calcule les métriques (Precision, Recall, F1, Accuracy, AUC) \n",
    "    en comparant le benchmark (Ground Truth) et le fichier de sortie (Predictions).\n",
    "    Sauvegarde un résumé CSV.\n",
    "    \"\"\"\n",
    "    benchmark_path = exp_config['benchmark']\n",
    "    output_path = exp_config['output']\n",
    "    exp_name = exp_config.get('experiment_name', 'Unknown')\n",
    "\n",
    "    if not output_path.exists():\n",
    "        console.print(f\"[red]Output file {output_path} not found. Cannot evaluate.[/red]\")\n",
    "        return\n",
    "\n",
    "    df_true = pd.read_csv(benchmark_path, encoding=\"utf-8\")\n",
    "    df_pred = pd.read_csv(output_path, encoding=\"utf-8\")\n",
    "\n",
    "    df_true = df_true[['content', 'label']].rename(columns={'label': 'target'})\n",
    "    df_pred = df_pred[['content', 'label']].rename(columns={'label': 'prediction'})\n",
    "\n",
    "    merged_df = pd.merge(df_true, df_pred, on='content', how='inner')\n",
    "    \n",
    "    if len(merged_df) == 0:\n",
    "        console.print(\"[red]No matching content found between benchmark and predictions.[/red]\")\n",
    "        return\n",
    "\n",
    "    def clean_label(val):\n",
    "        if isinstance(val, (int, float)):\n",
    "            return int(val)\n",
    "        s = str(val).lower().strip()\n",
    "        if s in ['oui', 'toxic', 'true', '1']:\n",
    "            return 1\n",
    "        if s in ['non', 'non-toxic', 'false', '0']:\n",
    "            return 0\n",
    "        return 0 \n",
    "\n",
    "    y_true = merged_df['target'].apply(clean_label)\n",
    "    y_pred = merged_df['prediction'].apply(clean_label)\n",
    "\n",
    "    results_row = {\"Model\": exp_name}\n",
    "    \n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    \n",
    "    results_row.update({\n",
    "        \"Precision_0\": report['0']['precision'],\n",
    "        \"Recall_0\":    report['0']['recall'],\n",
    "        \"F1_0\":        report['0']['f1-score'],\n",
    "        \"Precision_1\": report['1']['precision'],\n",
    "        \"Recall_1\":    report['1']['recall'],\n",
    "        \"F1_1\":        report['1']['f1-score'],\n",
    "        \"Accuracy\":    report['accuracy'],\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        roc = roc_auc_score(y_true, y_pred)\n",
    "        results_row[\"ROC_AUC\"] = roc\n",
    "    except Exception:\n",
    "        results_row[\"ROC_AUC\"] = 0.0\n",
    "\n",
    "    table = Table(title=f\"Results for {exp_name}\")\n",
    "    for key in results_row.keys():\n",
    "        table.add_column(key, justify=\"center\")\n",
    "    \n",
    "    row_values = [f\"{v:.4f}\" if isinstance(v, float) else str(v) for v in results_row.values()]\n",
    "    table.add_row(*row_values)\n",
    "    console.print(table)\n",
    "\n",
    "    summary_path = output_path.parent / \"metrics_summary.csv\"\n",
    "    \n",
    "    new_row_df = pd.DataFrame([results_row])\n",
    "    \n",
    "    if summary_path.exists():\n",
    "        existing_summary = pd.read_csv(summary_path)\n",
    "        existing_summary = existing_summary[existing_summary[\"Model\"] != exp_name]\n",
    "        final_summary = pd.concat([existing_summary, new_row_df], ignore_index=True)\n",
    "    else:\n",
    "        final_summary = new_row_df\n",
    "        \n",
    "    final_summary.to_csv(summary_path, index=False)\n",
    "    console.print(f\"[green]Metrics saved to {summary_path}[/green]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b09538a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mload_config\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_config' is not defined"
     ]
    }
   ],
   "source": [
    "config = load_config(\"config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c4d3abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config = config_experiment(\"rec_soap_test\", config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aba4b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = config[\"global\"][\"results_dir\"]\n",
    "df = load_benchmark(exp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de7b2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_id</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anon_msg_468ffd36870c</td>\n",
       "      <td>AYAAAAAAAAAAAA LES CRACKHEAD ANTI MIGRANT BORD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anon_msg_c30ce8c67bac</td>\n",
       "      <td>Bordel le gars chantait 'FN souffrance' alors ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anon_msg_a7be822bc051</td>\n",
       "      <td>Je vois que ça ddb en masse\\nComme en dictatur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anon_msg_8a2c7da3ff85</td>\n",
       "      <td>vous tenez là ? persoent c'est chaud depuis hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anon_msg_b20f2e8b51ed</td>\n",
       "      <td>Le racisme est devenu le crime ultime en Occid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>anon_msg_a3bb41085bd2</td>\n",
       "      <td>que j’entende plus un média dire le danger c’e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>anon_msg_835f5f8a3e25</td>\n",
       "      <td>il raconte absolument n'importe quoi non stop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>anon_msg_5de411f54a1b</td>\n",
       "      <td>mais qu'est ce qu'il raconte saint nikos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>anon_msg_48b9b19e3c3b</td>\n",
       "      <td>Oui el famoso 200 bordel\\n:rire:\\nLE QI bordel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>anon_msg_2f85a6bc5bea</td>\n",
       "      <td>Hello, si on est myope pour bosser dans l'admi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1388 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     msg_id  \\\n",
       "0     anon_msg_468ffd36870c   \n",
       "1     anon_msg_c30ce8c67bac   \n",
       "2     anon_msg_a7be822bc051   \n",
       "3     anon_msg_8a2c7da3ff85   \n",
       "4     anon_msg_b20f2e8b51ed   \n",
       "...                     ...   \n",
       "1383  anon_msg_a3bb41085bd2   \n",
       "1384  anon_msg_835f5f8a3e25   \n",
       "1385  anon_msg_5de411f54a1b   \n",
       "1386  anon_msg_48b9b19e3c3b   \n",
       "1387  anon_msg_2f85a6bc5bea   \n",
       "\n",
       "                                                content  label  \n",
       "0     AYAAAAAAAAAAAA LES CRACKHEAD ANTI MIGRANT BORD...      1  \n",
       "1     Bordel le gars chantait 'FN souffrance' alors ...      1  \n",
       "2     Je vois que ça ddb en masse\\nComme en dictatur...      1  \n",
       "3     vous tenez là ? persoent c'est chaud depuis hi...      1  \n",
       "4     Le racisme est devenu le crime ultime en Occid...      0  \n",
       "...                                                 ...    ...  \n",
       "1383  que j’entende plus un média dire le danger c’e...      0  \n",
       "1384      il raconte absolument n'importe quoi non stop      0  \n",
       "1385           mais qu'est ce qu'il raconte saint nikos      0  \n",
       "1386  Oui el famoso 200 bordel\\n:rire:\\nLE QI bordel...      0  \n",
       "1387  Hello, si on est myope pour bosser dans l'admi...      0  \n",
       "\n",
       "[1388 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c88ae6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_id</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>anon_msg_5ff0a5549f65</td>\n",
       "      <td>des bovins mon pote, j'ai jamais vu ça sauf en...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>anon_msg_2ea521264d58</td>\n",
       "      <td>Cet accent du sud dégueulasse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>anon_msg_99e41015a911</td>\n",
       "      <td>Joffrin, je serais capable de faire des trucs ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>anon_msg_31edc839b8b8</td>\n",
       "      <td>D'accord le julf, mais vous n'êtes pas BLANC.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>anon_msg_15c39b3b7e9a</td>\n",
       "      <td>C'est Siemens Espagne hein... Pas le PDG du gr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>anon_msg_7b8c238d5b51</td>\n",
       "      <td>AYAAAAA c'est exactement ça, il baise et ça le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>anon_msg_f46adea9c17b</td>\n",
       "      <td>comment ça fait pitié ton bail cousin juste ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>anon_msg_e38b90366618</td>\n",
       "      <td>laissons le mourir, agonisant. j'espère que le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     msg_id  \\\n",
       "650   anon_msg_5ff0a5549f65   \n",
       "208   anon_msg_2ea521264d58   \n",
       "427   anon_msg_99e41015a911   \n",
       "677   anon_msg_31edc839b8b8   \n",
       "1272  anon_msg_15c39b3b7e9a   \n",
       "239   anon_msg_7b8c238d5b51   \n",
       "1009  anon_msg_f46adea9c17b   \n",
       "528   anon_msg_e38b90366618   \n",
       "\n",
       "                                                content  label  \n",
       "650   des bovins mon pote, j'ai jamais vu ça sauf en...      0  \n",
       "208                       Cet accent du sud dégueulasse      1  \n",
       "427   Joffrin, je serais capable de faire des trucs ...      1  \n",
       "677       D'accord le julf, mais vous n'êtes pas BLANC.      1  \n",
       "1272  C'est Siemens Espagne hein... Pas le PDG du gr...      0  \n",
       "239   AYAAAAA c'est exactement ça, il baise et ça le...      1  \n",
       "1009  comment ça fait pitié ton bail cousin juste ar...      0  \n",
       "528   laissons le mourir, agonisant. j'espère que le...      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df.sample(n=8, random_state=42)\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "076517fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = PREDICTOR_MAP[exp_config['predictor']](exp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "205f8189",
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy = \"http://127.0.0.1:10809\"\n",
    "os.environ['HTTP_PROXY'] = proxy\n",
    "os.environ['HTTPS_PROXY'] = proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c49994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭─</span> QLoRA Utility <span style=\"color: #008080; text-decoration-color: #008080\">─╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">QLoRA Handler</span><span style=\"color: #008080; text-decoration-color: #008080\">   │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m╭─\u001b[0m QLoRA Utility \u001b[36m─╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[1;32mQLoRA Handler\u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m╰─────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139f906dc56b43118f0349ba9707dcaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059f76214c83431797eed2b69a5f7d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictor.initialise_predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"content\"].tolist()\n",
    "batch_results = predictor.predict_batch(texts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0098339",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "output_filename = Path(exp_config['output']).name \n",
    "output_path = result_dir / output_filename\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size), desc=\"Batch Inference\"):\n",
    "    batch = texts[i:i + batch_size]\n",
    "    batch_results = predictor.predict_batch(batch) \n",
    "    results.extend(batch_results)\n",
    "    \n",
    "    if i % (batch_size * 10) == 0:\n",
    "        pd.DataFrame({\n",
    "            \"content\": texts[:len(results)], \n",
    "            \"label\": results\n",
    "        }).to_csv(output_path, index=False)\n",
    "\n",
    "pd.DataFrame({\"content\": texts, \"label\": results}).to_csv(output_path, index=False)\n",
    "print(f\"Final results saved at {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87236b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭─</span> QLoRA Utility <span style=\"color: #008080; text-decoration-color: #008080\">─╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│ </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">QLoRA Handler</span><span style=\"color: #008080; text-decoration-color: #008080\">   │</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m╭─\u001b[0m QLoRA Utility \u001b[36m─╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m\u001b[36m \u001b[0m\u001b[1;32mQLoRA Handler\u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m\u001b[36m│\u001b[0m\n",
       "\u001b[36m╰─────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea43281ac04e4fbd9b1c51464800a709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_predictions_batched(exp_config, df_sample, batch_size=exp_config.get(\"batch_size\", 8), result_dir=\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bceaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if exp_config.get(\"gpu_parallel\", False):\n",
    "    \n",
    "else:\n",
    "    run_predictions(exp_config, df, result_dir=Path(result_dir))\n",
    "evaluate_predictions(exp_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SJTU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
