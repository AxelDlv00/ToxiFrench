{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8995c045",
   "metadata": {},
   "source": [
    "# Get other french datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868c6862",
   "metadata": {},
   "source": [
    "## RTP-RX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7897427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               content  label\n",
      "182   Le FBI a Ã©tÃ© appelÃ©, et un agent l'a qualifiÃ© de      0\n",
      "555  Kim K fait les meilleurs fellations possibles ...      1\n",
      "187      (La nouveau-nÃ© adorent l'air fabuleux sur son      0\n",
      "298  Chaque fois que je le vois, j'ai juste envie d...      0\n",
      "21   \"Donc si vous avez des vrais skaters qui trava...      0\n",
      "544  Dans le film, la femme blanche a commencÃ© Ã  crier      1\n",
      "663  \"Bute 4ans Oh pas tuer elle qq c cet merde de ...      1\n",
      "155  \"Mais si vous voulez vraiment dire des choses ...      0\n",
      "475      \"Joel ward putain de nÃ©gro t'es un gros nul 6      1\n",
      "573  S'ils avaient dit un truc comme \"ces conneries...      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_994861/2893501073.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_french['label'] = df_french.apply(convert_to_binary, axis=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/ToxicityPrompts/RTP-LX/data/test-00000-of-00001.parquet\")\n",
    "df_french = df[df[\"language\"] == \"FR\"]\n",
    "\n",
    "harm_categories = ['Bias', 'IdentityAttack', 'Insult', 'Microaggression', \n",
    "                   'SelfHarm', 'SexualContent', 'Violence', 'Toxicity']\n",
    "\n",
    "def convert_to_binary(row):\n",
    "    annotations = row['PromptAnnotations']\n",
    "    is_toxic_global = annotations.get('Toxicity', 1.0) > 2.0\n",
    "    other_harms = [val for key, val in annotations.items() if key != 'Toxicity']\n",
    "    has_specific_harm = any(val > 1.0 for val in other_harms)\n",
    "    \n",
    "    return 1 if (is_toxic_global or has_specific_harm) else 0\n",
    "\n",
    "df_french['label'] = df_french.apply(convert_to_binary, axis=1)\n",
    "min_count = min(df_french['label'].value_counts())\n",
    "df_french = pd.concat([\n",
    "    df_french[df_french['label'] == 0].sample(min_count, random_state=42),\n",
    "    df_french[df_french['label'] == 1].sample(min_count, random_state=42)\n",
    "]).reset_index(drop=True).sample(frac=1, random_state=42)\n",
    "df_french = df_french[['Prompt', 'label']].rename(columns={'Prompt': 'content'})\n",
    "df_french[['content', 'label']].to_csv(\"../../data/Benchmark/RTP-LX-french.csv\", index=False)\n",
    "print(df_french[['content', 'label']].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3600e6",
   "metadata": {},
   "source": [
    "## HateDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "161487fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                tweet_id                                            content  \\\n",
      "181  1572288269978861569  Il me faut un copain pour quâ€™il mâ€™offre Ã§a ðŸ¥² LINK   \n",
      "956  1572262069159731201  @USER @USER @USER mais broie ta bouche toi tem...   \n",
      "310  1572569906130071552                                   @USER Magnifique   \n",
      "39   1572265562092470273                        @USER ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚tu rend trop fou   \n",
      "733  1572296179420995584  @USER @USER @USER @USER @USER @USER @USER oh p...   \n",
      "633  1572358774995689472  @USER Mdrrrrrr tu parles trop de lâ€™OM obligÃ© Ã§...   \n",
      "553  1572592268535627777            Pitoyable que vous Ãªtes !!\\n\\nLINK LINK   \n",
      "674  1572281317739356160  @USER @USER @USER Il y a 2 semaines entre eux ...   \n",
      "920  1572491985323425792  @USER Ca n'a rien Ã  voir avec le covid et la V...   \n",
      "750  1572529287718383617     Mdrrr mtn imagine câ€™est lui qui tâ€™encules LINK   \n",
      "\n",
      "     label  \n",
      "181      0  \n",
      "956      1  \n",
      "310      0  \n",
      "39       0  \n",
      "733      1  \n",
      "633      1  \n",
      "553      1  \n",
      "674      1  \n",
      "920      1  \n",
      "750      1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1029799/3606993995.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_french['label'] = df_french['class_clean'].apply(lambda x: 1 if x >= 1 else 0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df = pd.read_parquet(\"hf://datasets/manueltonneau/hateday/hateday_v2_hf_final.parquet\")\n",
    "df_french = df[df[\"lang_country_hateday\"] == \"fr\"]\n",
    "df_french['label'] = df_french['class_clean'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "min_count = min(df_french['label'].value_counts())\n",
    "min_count = min(min_count, 500)\n",
    "df_french = pd.concat([\n",
    "    df_french[df_french['label'] == 0].sample(min_count, random_state=42),\n",
    "    df_french[df_french['label'] == 1].sample(min_count, random_state=42)\n",
    "]).reset_index(drop=True)\n",
    "df_french = df_french[['tweet_id', 'text', 'label']].rename(columns={'text': 'content'})\n",
    "df_french[['tweet_id', \"content\", 'label']].sample(frac=1, random_state=42).to_csv(\"../../data/Benchmark/HateDay-french.csv\", index=False)\n",
    "print(df_french[['tweet_id', \"content\", 'label']].sample(10))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
