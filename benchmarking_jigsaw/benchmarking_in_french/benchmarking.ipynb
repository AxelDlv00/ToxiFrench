{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540ef521",
   "metadata": {},
   "source": [
    "# Benchmarking classifiers on this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30c5457",
   "metadata": {},
   "source": [
    "| Model Name                                           | Size   | Type    | Notes                                                          |\n",
    "| ---------------------------------------------------- | ------ | ------- | -------------------------------------------------------------- |\n",
    "| `unitary/toxic-bert`                                 | \\~110M | BERT    | Classic English toxicity model trained on Jigsaw.              |\n",
    "| `microsoft/Multilingual-Toxic-XLMR`                  | \\~270M | XLM-R   | Multilingual support (English, French, etc.), trained on mTCR. |\n",
    "| `Davlan/bert-base-multilingual-cased-toxic-comments` | \\~110M | BERT    | French/English support, Jigsaw-based.                          |\n",
    "| `facebook/roberta-hate-speech-dynabench`             | \\~355M | RoBERTa | English hate speech classifier.                                |\n",
    "| `cardiffnlp/twitter-roberta-base-offensive`          | \\~125M | RoBERTa | Robust for social media, English only.                         |\n",
    "| `CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment`  | \\~110M | BERT    | Good if testing multilingual range.                            |\n",
    "| `papluca/xlm-roberta-base-language-detection`        | -      | XLM-R   | Not toxicity, but to test misclassification across languages.  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f58fa2",
   "metadata": {},
   "source": [
    "| Model              | Strengths                                                  | Weaknesses            |\n",
    "| ------------------ | ---------------------------------------------------------- | --------------------- |\n",
    "| `gpt-4o`           | Best zero-shot classification, supports nuanced reasoning. | Expensive, API-only.  |\n",
    "| `gpt-3.5-turbo`    | Fast, decent reasoning.                                    | Weaker on edge cases. |\n",
    "| `text-davinci-003` | Classic prompt-following.                                  | Obsolete vs GPT-4.    |\n",
    "\n",
    "Classify the following message as toxic (1) or non-toxic (0):\n",
    "<text>\n",
    "Answer: \n",
    "\n",
    "| Model             | Notes                                     |\n",
    "| ----------------- | ----------------------------------------- |\n",
    "| `claude-3-opus`   | Very high performance, nuanced judgement. |\n",
    "| `claude-3-sonnet` | Balanced latency and cost.                |\n",
    "| `claude-instant`  | Faster but less accurate.                 |\n",
    "\n",
    "\n",
    "\n",
    "| Model                                | Prompt Type | Notes                                                      |\n",
    "| ------------------------------------ | ----------- | ---------------------------------------------------------- |\n",
    "| `mistralai/Mistral-7B-Instruct-v0.2` | Chat        | Strong general model, use chain-of-thought for edge cases. |\n",
    "| `Qwen/Qwen1.5-7B-Chat`               | Chat        | Very good in French & toxicity detection.                  |\n",
    "| `meta-llama/Llama-3-8b-chat-hf`      | Chat        | Top-tier general performance.                              |\n",
    "\n",
    "| Model                                   | Size | Notes                                       |\n",
    "| --------------------------------------- | ---- | ------------------------------------------- |\n",
    "| `Qwen/Qwen1.5-0.5B`                     | 0.5B | Lightest usable Qwen.                       |\n",
    "| `mistralai/Mistral-7B-Instruct-v0.1`    | 7B   | Efficient and strong for offline inference. |\n",
    "| `NousResearch/TinyLlama-1.1B-Chat-v1.0` | 1.1B | Useful for embedded or quick deployments.   |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922dd626",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103136ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Optional: For calling OpenAI or HF models\n",
    "# from openai import OpenAI\n",
    "# from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80fec44",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345da9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"..\")\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "BENCHMARK_PATH = DATA_DIR / \"benchmark\" / \"benchmark.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97e432b",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4bff82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_id</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anon_msg_1a684cbe350a</td>\n",
       "      <td>Bien manger c'est le début du bonheur.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anon_msg_0cc5e09d68f9</td>\n",
       "      <td>non comparaison à l’ouzo t’as rien suivi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anon_msg_bc0764308f82</td>\n",
       "      <td>Faut être très fragile pour boucler sur un jeu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anon_msg_2700e892bb78</td>\n",
       "      <td>Non juste pour montrer que ça vaut le coup d'a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anon_msg_41523912b7c8</td>\n",
       "      <td>Allez on rejoint les golemz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  msg_id                                            content  \\\n",
       "0  anon_msg_1a684cbe350a             Bien manger c'est le début du bonheur.   \n",
       "1  anon_msg_0cc5e09d68f9           non comparaison à l’ouzo t’as rien suivi   \n",
       "2  anon_msg_bc0764308f82  Faut être très fragile pour boucler sur un jeu...   \n",
       "3  anon_msg_2700e892bb78  Non juste pour montrer que ça vaut le coup d'a...   \n",
       "4  anon_msg_41523912b7c8                        Allez on rejoint les golemz   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(BENCHMARK_PATH, encoding=\"utf-8\")\n",
    "df = df.dropna(subset=[\"content\", \"label\"])\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495491e3",
   "metadata": {},
   "source": [
    "## Define prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4789baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_predict(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Replace this with a real model inference.\n",
    "    Returns 1 if the message seems toxic, 0 otherwise.\n",
    "    \"\"\"\n",
    "    keywords = [\"fragile\", \"vote truqué\", \"golemz\"]\n",
    "    return int(any(word in text.lower() for word in keywords))\n",
    "\n",
    "# If using HuggingFace (example):\n",
    "# classifier = pipeline(\"text-classification\", model=\"unitary/toxic-bert\")\n",
    "# def hf_predict(text):\n",
    "#     out = classifier(text)[0]\n",
    "#     return int(out[\"label\"] == \"TOXIC\" and out[\"score\"] > 0.5)\n",
    "\n",
    "# If using OpenAI GPT model (requires API key):\n",
    "# import openai\n",
    "# openai.api_key = \"your-api-key\"\n",
    "# def gpt_predict(text: str) -> int:\n",
    "#     prompt = f\"Classify the following message as toxic (1) or non-toxic (0):\\n\\n{text}\\n\\nAnswer:\"\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#         model=\"gpt-4o\",\n",
    "#         messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "#         temperature=0\n",
    "#     )\n",
    "#     return int(\"1\" in response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe256d9",
   "metadata": {},
   "source": [
    "## Run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa4c51ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa279f426c7742fa8369920472f2b316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df[\"prediction\"] = df[\"content\"].progress_apply(mock_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84d842",
   "metadata": {},
   "source": [
    "## Metrics & Report        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85668e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.968     0.999     0.984     21274\n",
      "           1      0.053     0.001     0.003       694\n",
      "\n",
      "    accuracy                          0.968     21968\n",
      "   macro avg      0.511     0.500     0.493     21968\n",
      "weighted avg      0.939     0.968     0.953     21968\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21256    18]\n",
      " [  693     1]]\n",
      "\n",
      "ROC AUC Score: 0.500\n"
     ]
    }
   ],
   "source": [
    "y_true = df[\"label\"]\n",
    "y_pred = df[\"prediction\"]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, digits=3))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "try:\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    print(f\"\\nROC AUC Score: {auc:.3f}\")\n",
    "except:\n",
    "    print(\"\\nROC AUC Score could not be computed (only one class present).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5b0c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SJTU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
