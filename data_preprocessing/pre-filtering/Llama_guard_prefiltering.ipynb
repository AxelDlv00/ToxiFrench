{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c784ded",
   "metadata": {},
   "source": [
    "# Prefiltering with [Llama-Guard-3-8B](https://huggingface.co/meta-llama/Llama-Guard-3-8B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9aa515",
   "metadata": {},
   "source": [
    "According to the [benchmark](./../../benchmarking/benchmark_summary.ipynb), Llama-guard may not have a good recall but it has a high precision (~93%), i.e. almost all the comments annotated as toxic by LlamaGuard are indeed (truly) toxic. Therefore, we will use it to prefilter [subsets](./../../data/subsets_Di/) to gather more toxic contents.\n",
    "\n",
    "We have already done such an annotation with [gemini 2.0 flash](gemini_prefiltering.ipynb), which has 96% of recall for the toxicity class. This ensures that almost all the (truly) toxic comments were annotated as toxic by Gemini. \n",
    "\n",
    "Therefore, we only need to look at the comments that Gemini has annotated as toxic if we want to gather the most toxicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b174835",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c631c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from detoxify import Detoxify\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "import warnings\n",
    "from tqdm.std import TqdmExperimentalWarning\n",
    "warnings.filterwarnings(\"ignore\", category=TqdmExperimentalWarning)\n",
    "from tqdm.rich import tqdm\n",
    "tqdm.pandas(desc=\"Prédiction Toxicité\")\n",
    "\n",
    "from rich.panel import Panel\n",
    "from rich.text import Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc6087c",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6310ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"../..\")\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "range_authorized = (6, 8) # (a,b) -> [a, a+1, ..., b-1]\n",
    "subsets = [f for f in os.listdir(DATA_DIR / \"subsets_Di\") if f.replace(\".csv\",\"\").replace(\"subset_\", \"\") in map(str, range(range_authorized[0], range_authorized[1]))]\n",
    "output_path = DATA_DIR / \"pre-filtering\" / f\"llamaguard_and_gemini_pre-filtered_{range_authorized[0]}_{range_authorized[1]}.csv\"\n",
    "gemini_annotated_path = DATA_DIR / \"pre-filtering\" / f\"gemini_pre-filtered_{range_authorized[0]}_{range_authorized[1]}.csv\"\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6fb26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HTTP_PROXY\"] = \"socks5h://127.0.0.1:1080\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"socks5h://127.0.0.1:1080\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00586e4",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e59d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loaded Gemini annotated data from ..<span style=\"color: #800080; text-decoration-color: #800080\">/../data/pre-filtering/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">gemini_pre-filtered_6_8.csv</span> with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60000</span> rows.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loaded Gemini annotated data from ..\u001b[35m/../data/pre-filtering/\u001b[0m\u001b[95mgemini_pre-filtered_6_8.csv\u001b[0m with \u001b[1;36m60000\u001b[0m rows.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Filtered Gemini data to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13664</span> rows with gemini_prediction == <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Filtered Gemini data to \u001b[1;36m13664\u001b[0m rows with gemini_prediction == \u001b[1;36m1\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_gemini = pd.read_csv(gemini_annotated_path, encoding='utf-8')\n",
    "console.print(f\"Loaded Gemini annotated data from {gemini_annotated_path} with {len(df_gemini)} rows.\")\n",
    "df_gemini = df_gemini[df_gemini['gemini_prediction'] == 1]\n",
    "console.print(f\"Filtered Gemini data to {len(df_gemini)} rows with gemini_prediction == 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87214cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loaded and concatenated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> subsets with a total of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60000</span> rows.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loaded and concatenated \u001b[1;36m2\u001b[0m subsets with a total of \u001b[1;36m60000\u001b[0m rows.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Filtered data to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13664</span> rows matching Gemini annotated msg_ids.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Filtered data to \u001b[1;36m13664\u001b[0m rows matching Gemini annotated msg_ids.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_id</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>topic</th>\n",
       "      <th>deleted</th>\n",
       "      <th>banned</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anon_msg_514998f35627</td>\n",
       "      <td>anon_user_9cca1e694b</td>\n",
       "      <td>la version chatgpt correspond beaucoup mieux à...</td>\n",
       "      <td>anon_topic_f16270da</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>anon_msg_3bdb9d77af1b</td>\n",
       "      <td>anon_user_6b122a9f24</td>\n",
       "      <td>oui l'auteur doit bien puer aussi avec ses vêt...</td>\n",
       "      <td>anon_topic_61bb448b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>anon_msg_a2963f6d9b53</td>\n",
       "      <td>anon_user_500456ebff</td>\n",
       "      <td>Comment trouvez vous le temps de lire un livre...</td>\n",
       "      <td>anon_topic_00f0fdf2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>anon_msg_13fc9507af7a</td>\n",
       "      <td>anon_user_a34644fa48</td>\n",
       "      <td>Propagande de quoi le parigot ? C'est la putai...</td>\n",
       "      <td>anon_topic_8c7a01ff</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>anon_msg_373bf377933b</td>\n",
       "      <td>anon_user_5cfcc99e11</td>\n",
       "      <td>Barres-toi sans donner de raison elle ne mérit...</td>\n",
       "      <td>anon_topic_bb3c1e80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59983</th>\n",
       "      <td>anon_msg_8adc932fedf0</td>\n",
       "      <td>anon_user_411a03406c</td>\n",
       "      <td>Islamiste et soumis à l'empire ça semble aller...</td>\n",
       "      <td>anon_topic_c0258430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59990</th>\n",
       "      <td>anon_msg_4b2f5ec1a08c</td>\n",
       "      <td>anon_user_3da6356e21</td>\n",
       "      <td>+ viol collectif et grossesse forcé des petite...</td>\n",
       "      <td>anon_topic_f17a8ddb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59991</th>\n",
       "      <td>anon_msg_752808fcf53c</td>\n",
       "      <td>anon_user_262aae22aa</td>\n",
       "      <td>Montagner prix Nobel de médecine = caca\\nUn pr...</td>\n",
       "      <td>anon_topic_1d0fa47b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59992</th>\n",
       "      <td>anon_msg_37fd53afd859</td>\n",
       "      <td>anon_user_3753c83248</td>\n",
       "      <td>ToastED\\nLes modos, vous avez aucune race à su...</td>\n",
       "      <td>anon_topic_2954fe72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>anon_msg_68679115d5f8</td>\n",
       "      <td>anon_user_0a624ffe86</td>\n",
       "      <td>Les meufs qui savent qu'elles nous plaisent, q...</td>\n",
       "      <td>anon_topic_d2868aa9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13664 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      msg_id                  user  \\\n",
       "5      anon_msg_514998f35627  anon_user_9cca1e694b   \n",
       "6      anon_msg_3bdb9d77af1b  anon_user_6b122a9f24   \n",
       "10     anon_msg_a2963f6d9b53  anon_user_500456ebff   \n",
       "12     anon_msg_13fc9507af7a  anon_user_a34644fa48   \n",
       "19     anon_msg_373bf377933b  anon_user_5cfcc99e11   \n",
       "...                      ...                   ...   \n",
       "59983  anon_msg_8adc932fedf0  anon_user_411a03406c   \n",
       "59990  anon_msg_4b2f5ec1a08c  anon_user_3da6356e21   \n",
       "59991  anon_msg_752808fcf53c  anon_user_262aae22aa   \n",
       "59992  anon_msg_37fd53afd859  anon_user_3753c83248   \n",
       "59998  anon_msg_68679115d5f8  anon_user_0a624ffe86   \n",
       "\n",
       "                                                 content                topic  \\\n",
       "5      la version chatgpt correspond beaucoup mieux à...  anon_topic_f16270da   \n",
       "6      oui l'auteur doit bien puer aussi avec ses vêt...  anon_topic_61bb448b   \n",
       "10     Comment trouvez vous le temps de lire un livre...  anon_topic_00f0fdf2   \n",
       "12     Propagande de quoi le parigot ? C'est la putai...  anon_topic_8c7a01ff   \n",
       "19     Barres-toi sans donner de raison elle ne mérit...  anon_topic_bb3c1e80   \n",
       "...                                                  ...                  ...   \n",
       "59983  Islamiste et soumis à l'empire ça semble aller...  anon_topic_c0258430   \n",
       "59990  + viol collectif et grossesse forcé des petite...  anon_topic_f17a8ddb   \n",
       "59991  Montagner prix Nobel de médecine = caca\\nUn pr...  anon_topic_1d0fa47b   \n",
       "59992  ToastED\\nLes modos, vous avez aucune race à su...  anon_topic_2954fe72   \n",
       "59998  Les meufs qui savent qu'elles nous plaisent, q...  anon_topic_d2868aa9   \n",
       "\n",
       "       deleted  banned  hour  \n",
       "5            1       0     1  \n",
       "6            1       0     0  \n",
       "10           0       0    11  \n",
       "12           1       1    14  \n",
       "19           1       0    11  \n",
       "...        ...     ...   ...  \n",
       "59983        0       0    14  \n",
       "59990        0       0    11  \n",
       "59991        1       0    12  \n",
       "59992        0       0     1  \n",
       "59998        0       0     2  \n",
       "\n",
       "[13664 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = [pd.read_csv(DATA_DIR / \"subsets_Di\" / f, encoding='utf-8') for f in subsets]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "console.print(f\"Loaded and concatenated {len(dfs)} subsets with a total of {len(df)} rows.\")\n",
    "df = df[df['msg_id'].isin(df_gemini['msg_id'])]\n",
    "console.print(f\"Filtered data to {len(df)} rows matching Gemini annotated msg_ids.\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f8ff35",
   "metadata": {},
   "source": [
    "## Define prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc004cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99c51ed20234a6086195dd1ee16f47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-Guard-3-8B\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=dtype, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83ec13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text: str):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"Dis quelque chose de toxique.\"},\n",
    "        {\"role\": \"assistant\", \"content\": text}\n",
    "    ]\n",
    "    input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(model.device)\n",
    "    output = model.generate(input_ids=input_ids, max_new_tokens=100, pad_token_id=0)\n",
    "    response = tokenizer.decode(output[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
    "    return ('unsafe' in response.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7123f09",
   "metadata": {},
   "source": [
    "## Run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b39529cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ef48a3978f47f7af70ba48841ff15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['llama_prediction'] = df[\"content\"].progress_apply(predict)\n",
    "df = df.dropna(subset=[\"llama_prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b053c8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭──────────────────────────────────────────────── Exemple 16879 ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span> laisse moi deviner, tu as 13 cm max et tu complexe car d'autres témoignent de leurs engins supérieur à 15 cm ? <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                                <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">LlamaGuard Prediction:</span> <span style=\"font-weight: bold\">1</span>                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m╭─\u001b[0m\u001b[35m───────────────────────────────────────────────\u001b[0m\u001b[35m Exemple 16879 \u001b[0m\u001b[35m────────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
       "\u001b[35m│\u001b[0m laisse moi deviner, tu as 13 cm max et tu complexe car d'autres témoignent de leurs engins supérieur à 15 cm ? \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                                \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m \u001b[33mLlamaGuard Prediction:\u001b[0m \u001b[1m1\u001b[0m                                                                                       \u001b[35m│\u001b[0m\n",
       "\u001b[35m╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭─────────────────────────────────────────────── Exemple 21347 ───────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span> T'inquiète pour moi tu seras toujours un salaud d'angliche qui mérite de finir au bucher pour venger Jeanne <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                                                                             <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">LlamaGuard Prediction:</span> <span style=\"font-weight: bold\">1</span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m╭─\u001b[0m\u001b[35m──────────────────────────────────────────────\u001b[0m\u001b[35m Exemple 21347 \u001b[0m\u001b[35m──────────────────────────────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
       "\u001b[35m│\u001b[0m T'inquiète pour moi tu seras toujours un salaud d'angliche qui mérite de finir au bucher pour venger Jeanne \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                                                                             \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m \u001b[33mLlamaGuard Prediction:\u001b[0m \u001b[1m1\u001b[0m                                                                                    \u001b[35m│\u001b[0m\n",
       "\u001b[35m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭───────────── Exemple 21249 ──────────────╮</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span> Les hommes blancs sont tellement cruels! <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                          <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">LlamaGuard Prediction:</span> <span style=\"font-weight: bold\">1</span>                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">╰──────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m╭─\u001b[0m\u001b[35m────────────\u001b[0m\u001b[35m Exemple 21249 \u001b[0m\u001b[35m─────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
       "\u001b[35m│\u001b[0m Les hommes blancs sont tellement cruels! \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                          \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m \u001b[33mLlamaGuard Prediction:\u001b[0m \u001b[1m1\u001b[0m                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m╰──────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭────────────── Exemple 20192 ───────────────╮</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span> Tél Aviv, c'est pas très occidental le goy <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                            <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">LlamaGuard Prediction:</span> <span style=\"font-weight: bold\">1</span>                   <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">╰────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m╭─\u001b[0m\u001b[35m─────────────\u001b[0m\u001b[35m Exemple 20192 \u001b[0m\u001b[35m──────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
       "\u001b[35m│\u001b[0m Tél Aviv, c'est pas très occidental le goy \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                            \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m \u001b[33mLlamaGuard Prediction:\u001b[0m \u001b[1m1\u001b[0m                   \u001b[35m│\u001b[0m\n",
       "\u001b[35m╰────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">╭─────────────────────── Exemple 58221 ────────────────────────╮</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span> Des sales gnouls ont voulu massacrer des blancs, c'est bon ? <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span> Vous pouvez ddb évidemment j'ai 1000 comptes                 <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span>                                                              <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">LlamaGuard Prediction:</span> <span style=\"font-weight: bold\">1</span>                                     <span style=\"color: #800080; text-decoration-color: #800080\">│</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">╰──────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m╭─\u001b[0m\u001b[35m──────────────────────\u001b[0m\u001b[35m Exemple 58221 \u001b[0m\u001b[35m───────────────────────\u001b[0m\u001b[35m─╮\u001b[0m\n",
       "\u001b[35m│\u001b[0m Des sales gnouls ont voulu massacrer des blancs, c'est bon ? \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m Vous pouvez ddb évidemment j'ai 1000 comptes                 \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m                                                              \u001b[35m│\u001b[0m\n",
       "\u001b[35m│\u001b[0m \u001b[33mLlamaGuard Prediction:\u001b[0m \u001b[1m1\u001b[0m                                     \u001b[35m│\u001b[0m\n",
       "\u001b[35m╰──────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_1 = df[df['llama_prediction'] == 1]\n",
    "\n",
    "for i, row in df_1.sample(5, random_state=42).iterrows():\n",
    "    content = Text(row['content'], style=\"bold\")\n",
    "    toxicity = f\"[yellow]LlamaGuard Prediction:[/yellow] [bold]{int(row['llama_prediction'])}[/bold]\"\n",
    "    panel = Panel.fit(\n",
    "        f\"{content}\\n\\n{toxicity}\",\n",
    "        title=f\"Exemple {i+1}\",\n",
    "        border_style=\"magenta\"\n",
    "    )\n",
    "    console.print(panel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a7b0428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_prediction\n",
       "False    11992\n",
       "True      1672\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['llama_prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50ff8533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SJTU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
